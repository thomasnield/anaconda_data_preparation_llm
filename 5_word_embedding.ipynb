{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2969a31d-55f9-473b-92af-ed8b88dd9059",
   "metadata": {},
   "source": [
    "# Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4335677d-0247-46d9-b93f-298f9ee4eafa",
   "metadata": {},
   "source": [
    "We learned a few ways to extract features from text data, and represent them as vectors. For the purposes of large language models and more ambitious natural language processing projects, word embeddings are a critical technique that will serve as a capstone to this course. \n",
    "\n",
    "**Word embeddings** are a technique for representing similar or related words to be close together in a vector space. It has allowed many breakthroughs in natural language processing, including the large language models we know today. The technical advantage they bring is they clump together words that are related and therefore reduce the number of dimensions needed, and by creating this density there is more data available for a given context. This greatly reduces the dimensionality and the number of features. \n",
    "\n",
    "Each word is mapped to a vector, and that vector takes up a point in space. Words that tend to be used together in a similar context are going to have vectors that are closer together. For example, \"dog\" and \"dalmation\" are likely to be close together. However, \"dog\" and \"cat\" are also going to be close together because those two words are often used together in the same sentence/context as well. The word \"pet\" should be close to those vectors as well. \n",
    "\n",
    "\"Candy\" and \"Chocolate\" will be close together, but not be anywhere near the \"dog\", \"pet\", or \"cat\"-related words. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0cc954-d473-4137-8f0b-e52420b4f727",
   "metadata": {},
   "source": [
    "![svg image](data:image/svg+xml;base64,<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!-- Created with Inkscape (http://www.inkscape.org/) -->

<svg
   width="126.52377mm"
   height="126.52377mm"
   viewBox="0 0 126.52377 126.52377"
   version="1.1"
   id="svg1"
   inkscape:version="1.3.1 (91b66b0, 2023-11-16)"
   sodipodi:docname="89maFwKN.svg"
   xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
   xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"
   xmlns="http://www.w3.org/2000/svg"
   xmlns:svg="http://www.w3.org/2000/svg">
  <sodipodi:namedview
     id="namedview1"
     pagecolor="#ffffff"
     bordercolor="#000000"
     borderopacity="0.25"
     inkscape:showpageshadow="2"
     inkscape:pageopacity="0.0"
     inkscape:pagecheckerboard="0"
     inkscape:deskcolor="#d1d1d1"
     inkscape:document-units="mm"
     inkscape:zoom="1.0387876"
     inkscape:cx="279.65293"
     inkscape:cy="233.44522"
     inkscape:window-width="1392"
     inkscape:window-height="1212"
     inkscape:window-x="2239"
     inkscape:window-y="25"
     inkscape:window-maximized="0"
     inkscape:current-layer="layer1" />
  <defs
     id="defs1" />
  <g
     inkscape:label="Layer 1"
     inkscape:groupmode="layer"
     id="layer1"
     transform="translate(-15.951054,-17.224575)">
    <rect
       style="fill:none;stroke:#000000;stroke-width:0.7;stroke-linecap:round;stroke-linejoin:round"
       id="rect1"
       width="125.82377"
       height="125.82377"
       x="16.301054"
       y="17.574575" />
    <path
       style="fill:#ff0000;stroke:#ff0000;stroke-width:0.834212;stroke-linecap:round;stroke-linejoin:round"
       d="M 16.36816,143.33123 47.562539,33.093973"
       id="path1" />
    <path
       style="fill:#ff8080;stroke:#ff8080;stroke-width:0.7;stroke-linecap:round;stroke-linejoin:round"
       d="M 16.301054,143.39834 51.450205,43.299678"
       id="path2" />
    <path
       style="fill:#ffd5d5;stroke:#ffaaaa;stroke-width:0.794599;stroke-linecap:round;stroke-linejoin:round"
       d="M 16.348353,143.35104 54.829303,58.119808"
       id="path3" />
    <path
       style="fill:#800000;stroke:#aa0000;stroke-width:0.7;stroke-linecap:round;stroke-linejoin:round"
       d="M 16.301054,143.39834 33.87563,39.479116"
       id="path4" />
    <path
       style="fill:#0000ff;stroke:#0000ff;stroke-width:0.7;stroke-linecap:round;stroke-linejoin:round"
       d="M 16.301054,143.39834 108.7586,101.88159"
       id="path5" />
    <text
       xml:space="preserve"
       style="font-size:4.9389px;font-family:Oswald;-inkscape-font-specification:Oswald;fill:#0000ff;stroke:#0000ff;stroke-width:0.7;stroke-linecap:round;stroke-linejoin:round"
       x="30.602945"
       y="36.677376"
       id="text5"><tspan
         sodipodi:role="line"
         id="tspan5"
         style="fill:#800000;stroke:none;stroke-width:0.7"
         x="30.602945"
         y="36.677376">Dog</tspan></text>
    <text
       xml:space="preserve"
       style="font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:4.9389px;font-family:Oswald;-inkscape-font-specification:'Oswald, Normal';font-variant-ligatures:normal;font-variant-caps:normal;font-variant-numeric:normal;font-variant-east-asian:normal;fill:#ff0000;stroke:none;stroke-width:0.7;stroke-linecap:round;stroke-linejoin:round"
       x="44.993721"
       y="29.475426"
       id="text5-9"><tspan
         sodipodi:role="line"
         id="tspan1">Dalmation</tspan></text>
    <text
       xml:space="preserve"
       style="font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:4.9389px;font-family:Oswald;-inkscape-font-specification:'Oswald, Normal';font-variant-ligatures:normal;font-variant-caps:normal;font-variant-numeric:normal;font-variant-east-asian:normal;fill:#ff5555;stroke:none;stroke-width:0.7;stroke-linecap:round;stroke-linejoin:round"
       x="52.19659"
       y="41.109615"
       id="text5-9-3"><tspan
         sodipodi:role="line"
         id="tspan7"
         x="52.19659"
         y="41.109615">Pet</tspan></text>
    <text
       xml:space="preserve"
       style="font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:4.9389px;font-family:Oswald;-inkscape-font-specification:'Oswald, Normal';font-variant-ligatures:normal;font-variant-caps:normal;font-variant-numeric:normal;font-variant-east-asian:normal;fill:#ff8080;stroke:none;stroke-width:0.7;stroke-linecap:round;stroke-linejoin:round"
       x="56.780956"
       y="55.135323"
       id="text5-9-3-8"><tspan
         sodipodi:role="line"
         id="tspan8"
         x="56.780956"
         y="55.135323">Cat</tspan></text>
    <text
       xml:space="preserve"
       style="font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:4.9389px;font-family:Oswald;-inkscape-font-specification:'Oswald, Normal';font-variant-ligatures:normal;font-variant-caps:normal;font-variant-numeric:normal;font-variant-east-asian:normal;fill:#0000ff;stroke:none;stroke-width:0.7;stroke-linecap:round;stroke-linejoin:round"
       x="114.30407"
       y="101.49208"
       id="text5-9-3-4"><tspan
         sodipodi:role="line"
         id="tspan9"
         x="114.30407"
         y="101.49208">Candy</tspan></text>
    <text
       xml:space="preserve"
       style="font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:4.9389px;font-family:Oswald;-inkscape-font-specification:'Oswald, Normal';font-variant-ligatures:normal;font-variant-caps:normal;font-variant-numeric:normal;font-variant-east-asian:normal;fill:#0066ff;stroke:none;stroke-width:0.7;stroke-linecap:round;stroke-linejoin:round"
       x="109.02439"
       y="115.92626"
       id="text5-9-3-4-8"><tspan
         sodipodi:role="line"
         id="tspan10"
         x="109.02439"
         y="115.92626">Chocolate</tspan></text>
    <path
       style="fill:#5599ff;stroke:#2a7fff;stroke-width:0.7;stroke-linecap:round;stroke-linejoin:round"
       d="M 16.36816,143.33123 105,114.61679"
       id="path9" />
  </g>
</svg>
)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75294571-7f85-434a-b3d3-ee82b35b1e19",
   "metadata": {},
   "source": [
    "So how are these word embeddings built? Generally speaking, a neural network or other algorithm will look around a word at the other words surrounding it. Then you will have a model that for a given word input, will output words with probabilities that they are associated with that word, or perhaps are the next word in a sentence. Think of a given input word outputting a probability distribution of other words that would surround it. Given a large enough text dataset, enough context can be constructed to productively predict relevant words. \n",
    "\n",
    "What gets really interesting is how contexts can be navigated. If you have a sufficient word embedding model you can take the vector for \"king,\" subtract the vector for \"man,\" add the vector for \"woman,\" and then land close to the vector for \"queen.\" Similarly, if I take the vector for \"shirt,\" subtract the vector \"man,\" then add the vector \"woman\" I might get the word \"blouse.\" Or if I take the vector for \"Berlin\" and subtract \"Germany,\" then add \"England\" I *should* get \"London.\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532526ac-c705-4be2-b977-46df6472d9b8",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdaf0df-f63d-4f66-9262-520d65bad957",
   "metadata": {},
   "source": [
    "Back in 2013, Tomas Mikolov at Google developed a famous method [Word2Vec](https://en.wikipedia.org/wiki/Word2vec) to build word embeddings. It has become the standard for word embeddings and many extensions like GloVe have been built around it. It can build two types of models for word embeddings: \n",
    "\n",
    "* CBOW - Continuous bag of word, builds a word embedding by predicting the current word based on its context.\n",
    "* Continuous Skip-Gram Model - Builds a word embedding by predicting the surrounding words given a current word.\n",
    "\n",
    "Word2Vec takes each current word and looks at a window of neighboring words, and the size of this window is configurable. Because of the efficiency of the algorithm, larger embeddings can be built efficiently from larger amounts of training data.\n",
    "\n",
    "An extension to Word2Vec, Global Vectors for Word Representation ([GloVe](https://en.wikipedia.org/wiki/GloVe)) was further developed in 2014 by researchers at Stanford. It incorporates Latent Semantic Analysis (LSA) and other techniques that better incorporate global word statistics. Instead of using a window for local context, it uses statistics across the entire text corpus. This results in substantial improvements to word embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e89b3bf-9fc3-4146-bd3b-fcb9ef388c84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
